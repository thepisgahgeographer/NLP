{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy Basics\n",
    "\n",
    "**spaCy** (https://spacy.io/) is an open-source Python library that parses and \"understands\" large volumes of text. Separate models are available that cater to specific languages (English, French, German, etc.).\n",
    "\n",
    "In this section we'll install and setup spaCy to work with Python, and then introduce some concepts related to Natural Language Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Setup\n",
    "\n",
    "Installation is a two-step process. First, install spaCy using either conda or pip. Next, download the specific model you want, based on language.<br> For more info visit https://spacy.io/usage/\n",
    "\n",
    "### 1. From the command line or terminal:\n",
    "> `conda install -c conda-forge spacy`\n",
    "> <br>*or*<br>\n",
    "> `pip install -U spacy`\n",
    "\n",
    "> ### Alternatively you can create a virtual environment:\n",
    "> `conda create -n spacyenv python=3 spacy=2`\n",
    "\n",
    "### 2. Next, also from the command line (you must run this as admin or use sudo):\n",
    "\n",
    "> `python -m spacy download en`\n",
    "\n",
    "> ### If successful, you should see a message like:\n",
    "\n",
    "> **`Linking successful`**<br>\n",
    "> `    C:\\Anaconda3\\envs\\spacyenv\\lib\\site-packages\\en_core_web_sm -->`<br>\n",
    "> `    C:\\Anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\data\\en`<br>\n",
    "> ` `<br>\n",
    "> `    You can now load the model via spacy.load('en')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\pandoras_box\\conda_envs\\lib\\site-packages (3.7.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement en (from versions: none)\n",
      "ERROR: No matching distribution found for en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting download\n",
      "  Downloading download-0.3.5-py3-none-any.whl (8.8 kB)\n"
     ]
    }
   ],
   "source": [
    "pip install spacy download en "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with spaCy in Python\n",
    "\n",
    "This is a typical set of instructions for importing and working with spaCy. Don't be surprised if this takes awhile - spaCy has a fairly large library to load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Pandoras_Box\\Conda_Envs\n",
      "\n",
      "  added / updated specs:\n",
      "    - spacy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    boltons-23.0.0             |   py39haa95532_0         421 KB\n",
      "    catalogue-2.0.10           |   py39haa95532_0          34 KB\n",
      "    cloudpathlib-0.16.0        |   py39haa95532_1          68 KB\n",
      "    conda-23.3.1               |   py39haa95532_0         972 KB\n",
      "    confection-0.1.4           |   py39h9909e9c_0          70 KB\n",
      "    cymem-2.0.6                |   py39hd77b12b_0          34 KB\n",
      "    cython-blis-0.7.9          |   py39h080aedc_0         4.4 MB\n",
      "    jsonpatch-1.33             |   py39haa95532_1          57 KB\n",
      "    jsonpointer-2.1            |     pyhd3eb1b0_0           9 KB\n",
      "    langcodes-3.3.0            |     pyhd3eb1b0_0         151 KB\n",
      "    murmurhash-1.0.7           |   py39hd77b12b_0          24 KB\n",
      "    preshed-3.0.6              |   py39h6c2663c_0          76 KB\n",
      "    pydantic-1.10.12           |   py39h2bbff1b_1         1.6 MB\n",
      "    ruamel.yaml-0.17.21        |   py39h2bbff1b_0         174 KB\n",
      "    ruamel.yaml.clib-0.2.6     |   py39h2bbff1b_1         101 KB\n",
      "    shellingham-1.5.0          |   py39haa95532_0          19 KB\n",
      "    spacy-3.7.2                |   py39hef0f399_0         6.2 MB\n",
      "    spacy-legacy-3.0.12        |   py39haa95532_0          50 KB\n",
      "    spacy-loggers-1.0.4        |   py39haa95532_0          21 KB\n",
      "    srsly-2.4.8                |   py39hd77b12b_1         553 KB\n",
      "    thinc-8.2.2                |   py39hf497b98_0         981 KB\n",
      "    typer-0.4.1                |   py39haa95532_0          49 KB\n",
      "    wasabi-0.9.1               |   py39haa95532_0          44 KB\n",
      "    weasel-0.3.4               |   py39haa95532_0          96 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        16.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  boltons            pkgs/main/win-64::boltons-23.0.0-py39haa95532_0 None\n",
      "  catalogue          pkgs/main/win-64::catalogue-2.0.10-py39haa95532_0 None\n",
      "  cloudpathlib       pkgs/main/win-64::cloudpathlib-0.16.0-py39haa95532_1 None\n",
      "  confection         pkgs/main/win-64::confection-0.1.4-py39h9909e9c_0 None\n",
      "  cymem              pkgs/main/win-64::cymem-2.0.6-py39hd77b12b_0 None\n",
      "  cython-blis        pkgs/main/win-64::cython-blis-0.7.9-py39h080aedc_0 None\n",
      "  jsonpatch          pkgs/main/win-64::jsonpatch-1.33-py39haa95532_1 None\n",
      "  jsonpointer        pkgs/main/noarch::jsonpointer-2.1-pyhd3eb1b0_0 None\n",
      "  langcodes          pkgs/main/noarch::langcodes-3.3.0-pyhd3eb1b0_0 None\n",
      "  murmurhash         pkgs/main/win-64::murmurhash-1.0.7-py39hd77b12b_0 None\n",
      "  preshed            pkgs/main/win-64::preshed-3.0.6-py39h6c2663c_0 None\n",
      "  pydantic           pkgs/main/win-64::pydantic-1.10.12-py39h2bbff1b_1 None\n",
      "  ruamel.yaml        pkgs/main/win-64::ruamel.yaml-0.17.21-py39h2bbff1b_0 None\n",
      "  ruamel.yaml.clib   pkgs/main/win-64::ruamel.yaml.clib-0.2.6-py39h2bbff1b_1 None\n",
      "  shellingham        pkgs/main/win-64::shellingham-1.5.0-py39haa95532_0 None\n",
      "  spacy              pkgs/main/win-64::spacy-3.7.2-py39hef0f399_0 None\n",
      "  spacy-legacy       pkgs/main/win-64::spacy-legacy-3.0.12-py39haa95532_0 None\n",
      "  spacy-loggers      pkgs/main/win-64::spacy-loggers-1.0.4-py39haa95532_0 None\n",
      "  srsly              pkgs/main/win-64::srsly-2.4.8-py39hd77b12b_1 None\n",
      "  thinc              pkgs/main/win-64::thinc-8.2.2-py39hf497b98_0 None\n",
      "  typer              pkgs/main/win-64::typer-0.4.1-py39haa95532_0 None\n",
      "  wasabi             pkgs/main/win-64::wasabi-0.9.1-py39haa95532_0 None\n",
      "  weasel             pkgs/main/win-64::weasel-0.3.4-py39haa95532_0 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               22.9.0-py39haa95532_0 --> 23.3.1-py39haa95532_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "jsonpatch-1.33       | 57 KB     |            |   0% \n",
      "jsonpatch-1.33       | 57 KB     | ##8        |  28% \n",
      "jsonpatch-1.33       | 57 KB     | ########## | 100% \n",
      "\n",
      "ruamel.yaml-0.17.21  | 174 KB    |            |   0% \n",
      "ruamel.yaml-0.17.21  | 174 KB    | ########## | 100% \n",
      "ruamel.yaml-0.17.21  | 174 KB    | ########## | 100% \n",
      "\n",
      "srsly-2.4.8          | 553 KB    |            |   0% \n",
      "srsly-2.4.8          | 553 KB    | ####       |  41% \n",
      "srsly-2.4.8          | 553 KB    | ########## | 100% \n",
      "srsly-2.4.8          | 553 KB    | ########## | 100% \n",
      "\n",
      "shellingham-1.5.0    | 19 KB     |            |   0% \n",
      "shellingham-1.5.0    | 19 KB     | ########## | 100% \n",
      "shellingham-1.5.0    | 19 KB     | ########## | 100% \n",
      "\n",
      "boltons-23.0.0       | 421 KB    |            |   0% \n",
      "boltons-23.0.0       | 421 KB    | #####3     |  53% \n",
      "boltons-23.0.0       | 421 KB    | ########## | 100% \n",
      "\n",
      "murmurhash-1.0.7     | 24 KB     |            |   0% \n",
      "murmurhash-1.0.7     | 24 KB     | ######7    |  68% \n",
      "murmurhash-1.0.7     | 24 KB     | ########## | 100% \n",
      "\n",
      "typer-0.4.1          | 49 KB     |            |   0% \n",
      "typer-0.4.1          | 49 KB     | ########## | 100% \n",
      "typer-0.4.1          | 49 KB     | ########## | 100% \n",
      "\n",
      "ruamel.yaml.clib-0.2 | 101 KB    |            |   0% \n",
      "ruamel.yaml.clib-0.2 | 101 KB    | ########## | 100% \n",
      "ruamel.yaml.clib-0.2 | 101 KB    | ########## | 100% \n",
      "\n",
      "wasabi-0.9.1         | 44 KB     |            |   0% \n",
      "wasabi-0.9.1         | 44 KB     | ########## | 100% \n",
      "wasabi-0.9.1         | 44 KB     | ########## | 100% \n",
      "\n",
      "spacy-3.7.2          | 6.2 MB    |            |   0% \n",
      "spacy-3.7.2          | 6.2 MB    | 1          |   2% \n",
      "spacy-3.7.2          | 6.2 MB    | 5          |   6% \n",
      "spacy-3.7.2          | 6.2 MB    | 9          |  10% \n",
      "spacy-3.7.2          | 6.2 MB    | #4         |  14% \n",
      "spacy-3.7.2          | 6.2 MB    | #8         |  19% \n",
      "spacy-3.7.2          | 6.2 MB    | ##4        |  24% \n",
      "spacy-3.7.2          | 6.2 MB    | ##9        |  30% \n",
      "spacy-3.7.2          | 6.2 MB    | ###5       |  36% \n",
      "spacy-3.7.2          | 6.2 MB    | ####2      |  43% \n",
      "spacy-3.7.2          | 6.2 MB    | ####9      |  50% \n",
      "spacy-3.7.2          | 6.2 MB    | #####7     |  57% \n",
      "spacy-3.7.2          | 6.2 MB    | ######6    |  66% \n",
      "spacy-3.7.2          | 6.2 MB    | #######5   |  76% \n",
      "spacy-3.7.2          | 6.2 MB    | ########5  |  86% \n",
      "spacy-3.7.2          | 6.2 MB    | #########6 |  96% \n",
      "spacy-3.7.2          | 6.2 MB    | ########## | 100% \n",
      "\n",
      "catalogue-2.0.10     | 34 KB     |            |   0% \n",
      "catalogue-2.0.10     | 34 KB     | ########## | 100% \n",
      "catalogue-2.0.10     | 34 KB     | ########## | 100% \n",
      "\n",
      "spacy-loggers-1.0.4  | 21 KB     |            |   0% \n",
      "spacy-loggers-1.0.4  | 21 KB     | ########## | 100% \n",
      "spacy-loggers-1.0.4  | 21 KB     | ########## | 100% \n",
      "\n",
      "thinc-8.2.2          | 981 KB    |            |   0% \n",
      "thinc-8.2.2          | 981 KB    | ##7        |  28% \n",
      "thinc-8.2.2          | 981 KB    | ########## | 100% \n",
      "thinc-8.2.2          | 981 KB    | ########## | 100% \n",
      "\n",
      "confection-0.1.4     | 70 KB     |            |   0% \n",
      "confection-0.1.4     | 70 KB     | ########## | 100% \n",
      "confection-0.1.4     | 70 KB     | ########## | 100% \n",
      "\n",
      "spacy-legacy-3.0.12  | 50 KB     |            |   0% \n",
      "spacy-legacy-3.0.12  | 50 KB     | ########## | 100% \n",
      "spacy-legacy-3.0.12  | 50 KB     | ########## | 100% \n",
      "\n",
      "weasel-0.3.4         | 96 KB     |            |   0% \n",
      "weasel-0.3.4         | 96 KB     | ########## | 100% \n",
      "weasel-0.3.4         | 96 KB     | ########## | 100% \n",
      "\n",
      "pydantic-1.10.12     | 1.6 MB    |            |   0% \n",
      "pydantic-1.10.12     | 1.6 MB    | ##3        |  23% \n",
      "pydantic-1.10.12     | 1.6 MB    | ########6  |  86% \n",
      "pydantic-1.10.12     | 1.6 MB    | ########## | 100% \n",
      "\n",
      "conda-23.3.1         | 972 KB    |            |   0% \n",
      "conda-23.3.1         | 972 KB    | ####7      |  48% \n",
      "conda-23.3.1         | 972 KB    | ########## | 100% \n",
      "conda-23.3.1         | 972 KB    | ########## | 100% \n",
      "\n",
      "cython-blis-0.7.9    | 4.4 MB    |            |   0% \n",
      "cython-blis-0.7.9    | 4.4 MB    | 8          |   9% \n",
      "cython-blis-0.7.9    | 4.4 MB    | ###6       |  36% \n",
      "cython-blis-0.7.9    | 4.4 MB    | #####6     |  57% \n",
      "cython-blis-0.7.9    | 4.4 MB    | #########  |  90% \n",
      "cython-blis-0.7.9    | 4.4 MB    | ########## | 100% \n",
      "\n",
      "preshed-3.0.6        | 76 KB     |            |   0% \n",
      "preshed-3.0.6        | 76 KB     | ########## | 100% \n",
      "preshed-3.0.6        | 76 KB     | ########## | 100% \n",
      "\n",
      "cymem-2.0.6          | 34 KB     |            |   0% \n",
      "cymem-2.0.6          | 34 KB     | ########## | 100% \n",
      "cymem-2.0.6          | 34 KB     | ########## | 100% \n",
      "\n",
      "jsonpointer-2.1      | 9 KB      |            |   0% \n",
      "jsonpointer-2.1      | 9 KB      | ########## | 100% \n",
      "\n",
      "langcodes-3.3.0      | 151 KB    |            |   0% \n",
      "langcodes-3.3.0      | 151 KB    | ########## | 100% \n",
      "langcodes-3.3.0      | 151 KB    | ########## | 100% \n",
      "\n",
      "cloudpathlib-0.16.0  | 68 KB     |            |   0% \n",
      "cloudpathlib-0.16.0  | 68 KB     | ##3        |  24% \n",
      "cloudpathlib-0.16.0  | 68 KB     | ########## | 100% \n",
      "cloudpathlib-0.16.0  | 68 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Pandoras_Box\\Conda_Envs\n",
      "\n",
      "  added / updated specs:\n",
      "    - spacy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    catalogue-2.0.10           |   py39hcbf5309_0          35 KB  conda-forge\n",
      "    conda-23.1.0               |   py39hcbf5309_0         912 KB  conda-forge\n",
      "    cymem-2.0.6                |   py39h415ef7b_3          34 KB  conda-forge\n",
      "    cython-blis-0.7.8          |   py39h5d4886f_0         5.6 MB  conda-forge\n",
      "    langcodes-3.3.0            |     pyhd8ed1ab_0         156 KB  conda-forge\n",
      "    murmurhash-1.0.8           |   py39h415ef7b_0          24 KB  conda-forge\n",
      "    pathy-0.10.2               |     pyhd8ed1ab_0          42 KB  conda-forge\n",
      "    preshed-3.0.7              |   py39h415ef7b_0          84 KB  conda-forge\n",
      "    pydantic-1.8.2             |   py39hb82d6ee_2         1.6 MB  conda-forge\n",
      "    python_abi-3.9             |           2_cp39           4 KB  conda-forge\n",
      "    ruamel.yaml-0.17.21        |   py39hb82d6ee_1         169 KB  conda-forge\n",
      "    ruamel.yaml.clib-0.2.6     |   py39hb82d6ee_1         112 KB  conda-forge\n",
      "    shellingham-1.5.4          |     pyhd8ed1ab_0          14 KB  conda-forge\n",
      "    spacy-3.2.4                |   py39hefe7e4c_0         8.9 MB  conda-forge\n",
      "    spacy-legacy-3.0.12        |     pyhd8ed1ab_0          28 KB  conda-forge\n",
      "    spacy-loggers-1.0.5        |     pyhd8ed1ab_0          21 KB  conda-forge\n",
      "    srsly-2.4.4                |   py39h415ef7b_0         506 KB  conda-forge\n",
      "    thinc-8.0.17               |   py39hefe7e4c_0         966 KB  conda-forge\n",
      "    typer-0.4.2                |     pyhd8ed1ab_0          45 KB  conda-forge\n",
      "    wasabi-0.10.1              |     pyhd8ed1ab_1          25 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        19.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  catalogue          conda-forge/win-64::catalogue-2.0.10-py39hcbf5309_0 None\n",
      "  cymem              conda-forge/win-64::cymem-2.0.6-py39h415ef7b_3 None\n",
      "  cython-blis        conda-forge/win-64::cython-blis-0.7.8-py39h5d4886f_0 None\n",
      "  langcodes          conda-forge/noarch::langcodes-3.3.0-pyhd8ed1ab_0 None\n",
      "  murmurhash         conda-forge/win-64::murmurhash-1.0.8-py39h415ef7b_0 None\n",
      "  pathy              conda-forge/noarch::pathy-0.10.2-pyhd8ed1ab_0 None\n",
      "  preshed            conda-forge/win-64::preshed-3.0.7-py39h415ef7b_0 None\n",
      "  pydantic           conda-forge/win-64::pydantic-1.8.2-py39hb82d6ee_2 None\n",
      "  python_abi         conda-forge/win-64::python_abi-3.9-2_cp39 None\n",
      "  ruamel.yaml        conda-forge/win-64::ruamel.yaml-0.17.21-py39hb82d6ee_1 None\n",
      "  ruamel.yaml.clib   conda-forge/win-64::ruamel.yaml.clib-0.2.6-py39hb82d6ee_1 None\n",
      "  shellingham        conda-forge/noarch::shellingham-1.5.4-pyhd8ed1ab_0 None\n",
      "  spacy              conda-forge/win-64::spacy-3.2.4-py39hefe7e4c_0 None\n",
      "  spacy-legacy       conda-forge/noarch::spacy-legacy-3.0.12-pyhd8ed1ab_0 None\n",
      "  spacy-loggers      conda-forge/noarch::spacy-loggers-1.0.5-pyhd8ed1ab_0 None\n",
      "  srsly              conda-forge/win-64::srsly-2.4.4-py39h415ef7b_0 None\n",
      "  thinc              conda-forge/win-64::thinc-8.0.17-py39hefe7e4c_0 None\n",
      "  typer              conda-forge/noarch::typer-0.4.2-pyhd8ed1ab_0 None\n",
      "  wasabi             conda-forge/noarch::wasabi-0.10.1-pyhd8ed1ab_1 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              pkgs/main::conda-22.9.0-py39haa95532_0 --> conda-forge::conda-23.1.0-py39hcbf5309_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "murmurhash-1.0.8     | 24 KB     |            |   0% \n",
      "murmurhash-1.0.8     | 24 KB     | ######5    |  65% \n",
      "murmurhash-1.0.8     | 24 KB     | ########## | 100% \n",
      "\n",
      "preshed-3.0.7        | 84 KB     |            |   0% \n",
      "preshed-3.0.7        | 84 KB     | ########## | 100% \n",
      "preshed-3.0.7        | 84 KB     | ########## | 100% \n",
      "\n",
      "pathy-0.10.2         | 42 KB     |            |   0% \n",
      "pathy-0.10.2         | 42 KB     | ########## | 100% \n",
      "pathy-0.10.2         | 42 KB     | ########## | 100% \n",
      "\n",
      "ruamel.yaml.clib-0.2 | 112 KB    |            |   0% \n",
      "ruamel.yaml.clib-0.2 | 112 KB    | ########## | 100% \n",
      "ruamel.yaml.clib-0.2 | 112 KB    | ########## | 100% \n",
      "\n",
      "typer-0.4.2          | 45 KB     |            |   0% \n",
      "typer-0.4.2          | 45 KB     | ###5       |  35% \n",
      "typer-0.4.2          | 45 KB     | ########## | 100% \n",
      "typer-0.4.2          | 45 KB     | ########## | 100% \n",
      "\n",
      "cymem-2.0.6          | 34 KB     |            |   0% \n",
      "cymem-2.0.6          | 34 KB     | ####6      |  47% \n",
      "cymem-2.0.6          | 34 KB     | ########## | 100% \n",
      "\n",
      "python_abi-3.9       | 4 KB      |            |   0% \n",
      "python_abi-3.9       | 4 KB      | ########## | 100% \n",
      "python_abi-3.9       | 4 KB      | ########## | 100% \n",
      "\n",
      "catalogue-2.0.10     | 35 KB     |            |   0% \n",
      "catalogue-2.0.10     | 35 KB     | ####5      |  46% \n",
      "catalogue-2.0.10     | 35 KB     | ########## | 100% \n",
      "\n",
      "cython-blis-0.7.8    | 5.6 MB    |            |   0% \n",
      "cython-blis-0.7.8    | 5.6 MB    |            |   0% \n",
      "cython-blis-0.7.8    | 5.6 MB    | #          |  11% \n",
      "cython-blis-0.7.8    | 5.6 MB    | ##9        |  30% \n",
      "cython-blis-0.7.8    | 5.6 MB    | #####2     |  53% \n",
      "cython-blis-0.7.8    | 5.6 MB    | #######5   |  75% \n",
      "cython-blis-0.7.8    | 5.6 MB    | ########## | 100% \n",
      "cython-blis-0.7.8    | 5.6 MB    | ########## | 100% \n",
      "\n",
      "spacy-legacy-3.0.12  | 28 KB     |            |   0% \n",
      "spacy-legacy-3.0.12  | 28 KB     | ########## | 100% \n",
      "spacy-legacy-3.0.12  | 28 KB     | ########## | 100% \n",
      "\n",
      "shellingham-1.5.4    | 14 KB     |            |   0% \n",
      "shellingham-1.5.4    | 14 KB     | ########## | 100% \n",
      "shellingham-1.5.4    | 14 KB     | ########## | 100% \n",
      "\n",
      "pydantic-1.8.2       | 1.6 MB    |            |   0% \n",
      "pydantic-1.8.2       | 1.6 MB    |            |   1% \n",
      "pydantic-1.8.2       | 1.6 MB    | ###6       |  36% \n",
      "pydantic-1.8.2       | 1.6 MB    | ########## | 100% \n",
      "pydantic-1.8.2       | 1.6 MB    | ########## | 100% \n",
      "\n",
      "langcodes-3.3.0      | 156 KB    |            |   0% \n",
      "langcodes-3.3.0      | 156 KB    | ########## | 100% \n",
      "langcodes-3.3.0      | 156 KB    | ########## | 100% \n",
      "\n",
      "conda-23.1.0         | 912 KB    |            |   0% \n",
      "conda-23.1.0         | 912 KB    | ##4        |  25% \n",
      "conda-23.1.0         | 912 KB    | ########## | 100% \n",
      "conda-23.1.0         | 912 KB    | ########## | 100% \n",
      "\n",
      "thinc-8.0.17         | 966 KB    |            |   0% \n",
      "thinc-8.0.17         | 966 KB    | 1          |   2% \n",
      "thinc-8.0.17         | 966 KB    | ########## | 100% \n",
      "thinc-8.0.17         | 966 KB    | ########## | 100% \n",
      "\n",
      "wasabi-0.10.1        | 25 KB     |            |   0% \n",
      "wasabi-0.10.1        | 25 KB     | ########## | 100% \n",
      "wasabi-0.10.1        | 25 KB     | ########## | 100% \n",
      "\n",
      "spacy-3.2.4          | 8.9 MB    |            |   0% \n",
      "spacy-3.2.4          | 8.9 MB    |            |   0% \n",
      "spacy-3.2.4          | 8.9 MB    | 9          |  10% \n",
      "spacy-3.2.4          | 8.9 MB    | #7         |  18% \n",
      "spacy-3.2.4          | 8.9 MB    | ###4       |  35% \n",
      "spacy-3.2.4          | 8.9 MB    | ####5      |  45% \n",
      "spacy-3.2.4          | 8.9 MB    | ######3    |  63% \n",
      "spacy-3.2.4          | 8.9 MB    | #######6   |  76% \n",
      "spacy-3.2.4          | 8.9 MB    | #########1 |  91% \n",
      "spacy-3.2.4          | 8.9 MB    | ########## | 100% \n",
      "\n",
      "spacy-loggers-1.0.5  | 21 KB     |            |   0% \n",
      "spacy-loggers-1.0.5  | 21 KB     | ########## | 100% \n",
      "spacy-loggers-1.0.5  | 21 KB     | ########## | 100% \n",
      "\n",
      "ruamel.yaml-0.17.21  | 169 KB    |            |   0% \n",
      "ruamel.yaml-0.17.21  | 169 KB    | ########5  |  85% \n",
      "ruamel.yaml-0.17.21  | 169 KB    | ########## | 100% \n",
      "\n",
      "srsly-2.4.4          | 506 KB    |            |   0% \n",
      "srsly-2.4.4          | 506 KB    | 3          |   3% \n",
      "srsly-2.4.4          | 506 KB    | ########## | 100% \n",
      "srsly-2.4.4          | 506 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 24.4.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a Doc object\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "doc\n",
    "# Print each token separately\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look very user-friendly, but right away we see some interesting things happen:\n",
    "1. Tesla is recognized to be a Proper Noun, not just a word at the start of a sentence\n",
    "2. U.S. is kept together as one entity (we call this a 'token')\n",
    "\n",
    "As we dive deeper into spaCy we'll see what each of these abbreviations mean and how they're derived. We'll also see how spaCy can interpret the last three tokens combined `$6 million` as referring to ***money***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# spaCy Objects\n",
    "\n",
    "After importing the spacy module in the cell above we loaded a **model** and named it `nlp`.<br>Next we created a **Doc** object by applying the model to our text, and named it `doc`.<br>spaCy also builds a companion **Vocab** object that we'll cover in later sections.<br>The **Doc** object that holds the processed text is our focus here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Pipeline\n",
    "When we run `nlp`, our text enters a *processing pipeline* that first breaks down the text and then performs a series of operations to tag, parse and describe the data.   Image source: https://spacy.io/usage/spacy-101#pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../pipeline1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see what components currently live in the pipeline. In later sections we'll learn how to disable components and add new ones as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x237cb1e8f98>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x237cb2852b0>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x237cb285360>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Tokenization\n",
    "The first step in processing text is to split up all the component parts (words & punctuation) into \"tokens\". These tokens are annotated inside the Doc object to contain descriptive information. We'll go into much more detail on tokenization in an upcoming lecture. For now, let's look at another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "n't ADV neg\n",
      "   SPACE \n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Tesla isn't   looking into startups anymore.\")\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `isn't` has been split into two tokens. spaCy recognizes both the root verb `is` and the negation attached to it. Notice also that both the extended whitespace and the period at the end of the sentence are assigned their own tokens.\n",
    "\n",
    "It's important to note that even though `doc2` contains processed information about each token, it also retains the original text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla isn't   looking into startups anymore."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Part-of-Speech Tagging (POS)\n",
    "The next step after splitting the text up into tokens is to assign parts of speech. In the above example, `Tesla` was recognized to be a ***proper noun***. Here some statistical modeling is required. For example, words that follow \"the\" are typically nouns.\n",
    "\n",
    "For a full list of POS Tags visit https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Dependencies\n",
    "We also looked at the syntactic dependencies assigned to each token. `Tesla` is identified as an `nsubj` or the ***nominal subject*** of the sentence.\n",
    "\n",
    "For a full list of Syntactic Dependencies visit https://spacy.io/api/annotation#dependency-parsing\n",
    "<br>A good explanation of typed dependencies can be found [here](https://nlp.stanford.edu/software/dependencies_manual.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].dep_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full name of a tag use `spacy.explain(tag)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Additional Token Attributes\n",
    "We'll see these again in upcoming lectures. For now we just want to illustrate some of the other information that spaCy assigns to tokens:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tag|Description|doc2[0].tag|\n",
    "|:------|:------:|:------|\n",
    "|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
    "|`.lemma_`|The base form of the word|`tesla`|\n",
    "|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|\n",
    "|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|\n",
    "|`.shape_`|The word shape â€“ capitalization, punctuation, digits|`Xxxxx`|\n",
    "|`.is_alpha`|Is the token an alpha character?|`True`|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "# Lemmas (the base form of the word):\n",
    "print(doc2[4].text)\n",
    "print(doc2[4].lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n",
      "VBG / verb, gerund or present participle\n"
     ]
    }
   ],
   "source": [
    "# Simple Parts-of-Speech & Detailed Tags:\n",
    "print(doc2[4].pos_)\n",
    "print(doc2[4].tag_ + ' / ' + spacy.explain(doc2[4].tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla: Xxxxx\n",
      "U.S. : X.X.\n"
     ]
    }
   ],
   "source": [
    "# Word Shapes:\n",
    "print(doc2[0].text+': '+doc2[0].shape_)\n",
    "print(doc[5].text+' : '+doc[5].shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Boolean Values:\n",
    "print(doc2[0].is_alpha)\n",
    "print(doc2[0].is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Spans\n",
    "Large Doc objects can be hard to work with at times. A **span** is a slice of Doc object in the form `Doc[start:stop]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "life_quote = doc3[16:30]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In upcoming lectures we'll see how to create Span objects using `Span()`. This will allow us to assign additional information to the Span."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Sentences\n",
    "Certain tokens inside a Doc object may also receive a \"start of sentence\" tag. While this doesn't immediately build a list of sentences, these tags enable the generation of sentence segments through `Doc.sents`. Later we'll write our own segmentation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next up: Tokenization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
